{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import h5py\n",
    "import myTelegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/net/big-tank/POOL/projects/fact/simulation/photon_stream/fact_tools/v.0.18.0/gamma_gustav_12',\n",
       " '/net/big-tank/POOL/projects/fact/simulation/photon_stream/fact_tools/v.0.18.0/proton_12',\n",
       " '/net/big-tank/POOL/projects/fact/simulation/photon_stream/fact_tools/v.0.18.0/gamma_werner_12']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to the data\n",
    "main_path = '/net/big-tank/POOL/projects/fact/simulation/photon_stream/fact_tools/v.0.18.0/'\n",
    "main_folder = [os.path.join(main_path, file) for file in os.listdir(main_path)]\n",
    "main_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format dataset and labels to fit into tensorflow\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, 46, 45, 1)).astype(np.float32)\n",
    "    labels = (np.arange(2) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_spe_extractor_mc_39.json\n",
      "output_spe_extractor_mc_72.json\n",
      "output_spe_extractor_mc_43.json\n",
      "output_spe_extractor_mc_83.json\n",
      "output_spe_extractor_mc_21.json\n"
     ]
    }
   ],
   "source": [
    "# Load mapping-dict to switch from hexagonal to matrix\n",
    "id_position = pickle.load(open(\"01_hexagonal_position_dict.p\", \"rb\"))\n",
    "\n",
    "data = []\n",
    "count = 0\n",
    "try:\n",
    "# Iterate over all three folders\n",
    "    for path in main_folder:\n",
    "\n",
    "        # Iterate over every file in the folder\n",
    "        for file in os.listdir(path):\n",
    "            file_path = os.path.join(path, file)\n",
    "\n",
    "            # Check if it is a json file\n",
    "            if '.json' in file_path:\n",
    "\n",
    "                # Open the file\n",
    "                with gzip.open(file_path) as f:\n",
    "                    count += 1\n",
    "\n",
    "                    # Iterate over every line and get the data\n",
    "                    for line in f:\n",
    "                        line_data = json.loads(line.decode('utf-8'))\n",
    "                        event_photons = line_data['PhotonArrivals_500ps']\n",
    "                        night = line_data['Night']\n",
    "                        run = line_data['Run']\n",
    "                        event = line_data['Event']\n",
    "                        fTotalEnergy = line_data['MCorsikaEvtHeader.fTotalEnergy']\n",
    "                        zd_deg = line_data['Zd_deg']\n",
    "                        az_deg = line_data['Az_deg']\n",
    "                        trigger = line_data['Trigger']\n",
    "\n",
    "                        label = True if 'gamma' in file_path else False\n",
    "\n",
    "                        input_matrix = np.zeros([46,45])\n",
    "                        for i in range(1440):\n",
    "                            x, y = id_position[i]\n",
    "                            input_matrix[int(x)][int(y)] = len(event_photons[i])\n",
    "                        data.append([input_matrix, label, night, run, event, fTotalEnergy, zd_deg, az_deg, trigger])\n",
    "                print(count, file)\n",
    "\n",
    "        # Dezip the data and convert it to numpy-arrays\n",
    "        pic, lab, night, run, event, fTotalEnergy, zd_deg, az_deg, trigger = zip(*data)\n",
    "        pic, lab = reformat(np.array(pic), np.array(lab))\n",
    "        night = np.array(night)\n",
    "        run = np.array(run)\n",
    "        event = np.array(event)\n",
    "        fTotalEnergy = np.array(fTotalEnergy)\n",
    "        zd_deg = np.array(zd_deg)\n",
    "        az_deg = np.array(az_deg)\n",
    "        trigger = np.array(trigger)\n",
    "\n",
    "        # Store every original folder into a single h5 file\n",
    "        with h5py.File('/fghfs/users/jbehnken/hdf5_files/'+path.rsplit('/', 1)[1]+'.h5', 'w') as hdf:\n",
    "            hdf.create_dataset('Image', data=pic, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Label', data=lab, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Night', data=night, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Run', data=run, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Event', data=event, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('fTotalEnergy', data=fTotalEnergy, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Zd_deg', data=zd_deg, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Az_deg', data=az_deg, compression='gzip', compression_opts=9)\n",
    "            hdf.create_dataset('Trigger', data=trigger, compression='gzip', compression_opts=9)\n",
    "\n",
    "        message = path.rsplit('/', 1)[1]+' has been processed.'\n",
    "        myTelegram.sendTelegram(message)\n",
    "except:\n",
    "    message = 'Leider ist ein Fehler aufgetreten.'\n",
    "    myTelegram.sendTelegram(message)\n",
    "    raise\n",
    "finally:\n",
    "    message = 'Berechnung wurde beendet.'\n",
    "    myTelegram.sendTelegram(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
