{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_folder_name = '29_ccccccffff'\n",
    "batch_size = 5000\n",
    "\n",
    "meta_loading_folder = '/fhgfs/users/jbehnken/make_Data/architectures/' + model_folder_name\n",
    "meta_loading_path = meta_loading_folder + '/' + model_folder_name.split('_')[-1] + '.meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchYielder(name):\n",
    "    file_path = '/fhgfs/users/jbehnken/make_Data/MC_preprocessed_images.h5'\n",
    "    #file_path = '/fhgfs/users/jbehnken/make_Data/MC_diffuse_preprocessed_images.h5'\n",
    "    #file_path = '/fhgfs/users/jbehnken/make_Data/MC_diffuse_flat_preprocessed_images.h5'\n",
    "    with h5py.File(file_path, 'r') as hdf:\n",
    "        items = list(hdf.items())[0][1].shape[0]\n",
    "        i = 0\n",
    "\n",
    "        while (i+1)*batch_size < items/4: # 160 factor to not process everything\n",
    "            images = np.array(hdf[name][ i*batch_size:(i+1)*batch_size ])\n",
    "\n",
    "            i += 1\n",
    "            print(i)\n",
    "            yield images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d_1 (5, 5, 1, 19)\n",
      "Conv2d_2 (5, 5, 19, 30)\n",
      "Conv2d_3 (5, 5, 30, 50)\n",
      "Conv2d_4 (5, 5, 50, 69)\n",
      "Conv2d_5 (5, 5, 69, 74)\n",
      "Conv2d_6 (5, 5, 74, 83)\n",
      "Fc_1 (83, 239)\n",
      "Fc_2 (239, 239)\n",
      "Fc_3 (239, 239)\n",
      "Fc_4 (239, 2)\n",
      "Model restored.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "gpu_config = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.2)\n",
    "session_conf = tf.ConfigProto(gpu_options=gpu_config, intra_op_parallelism_threads=18, inter_op_parallelism_threads=18)\n",
    "\n",
    "\n",
    "with tf.Session(config=session_conf) as sess:\n",
    "    saver = tf.train.import_meta_graph(meta_loading_path)    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint(meta_loading_folder))\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #print(sess.graph.get_operations())\n",
    "    \n",
    "    try:\n",
    "        conv2d_1_weights = graph.get_tensor_by_name(\"conv2d_1/W:0\")\n",
    "        conv2d_1_biases = graph.get_tensor_by_name(\"conv2d_1/B:0\")\n",
    "        print('Conv2d_1', conv2d_1_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_2_weights = graph.get_tensor_by_name(\"conv2d_2/W:0\")\n",
    "        conv2d_2_biases = graph.get_tensor_by_name(\"conv2d_2/B:0\")\n",
    "        print('Conv2d_2', conv2d_2_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_3_weights = graph.get_tensor_by_name(\"conv2d_3/W:0\")\n",
    "        conv2d_3_biases = graph.get_tensor_by_name(\"conv2d_3/B:0\")\n",
    "        print('Conv2d_3', conv2d_3_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_4_weights = graph.get_tensor_by_name(\"conv2d_4/W:0\")\n",
    "        conv2d_4_biases = graph.get_tensor_by_name(\"conv2d_4/B:0\")\n",
    "        print('Conv2d_4', conv2d_4_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_5_weights = graph.get_tensor_by_name(\"conv2d_5/W:0\")\n",
    "        conv2d_5_biases = graph.get_tensor_by_name(\"conv2d_5/B:0\")\n",
    "        print('Conv2d_5', conv2d_5_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_6_weights = graph.get_tensor_by_name(\"conv2d_6/W:0\")\n",
    "        conv2d_6_biases = graph.get_tensor_by_name(\"conv2d_6/B:0\")\n",
    "        print('Conv2d_6', conv2d_6_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_1_weights = graph.get_tensor_by_name(\"fc_1/W:0\")\n",
    "        fc_1_biases = graph.get_tensor_by_name(\"fc_1/B:0\")\n",
    "        print('Fc_1', fc_1_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_2_weights = graph.get_tensor_by_name(\"fc_2/W:0\")\n",
    "        fc_2_biases = graph.get_tensor_by_name(\"fc_2/B:0\")\n",
    "        print('Fc_2', fc_2_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_3_weights = graph.get_tensor_by_name(\"fc_3/W:0\")\n",
    "        fc_3_biases = graph.get_tensor_by_name(\"fc_3/B:0\")\n",
    "        print('Fc_3', fc_3_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_4_weights = graph.get_tensor_by_name(\"output/W:0\")\n",
    "        fc_4_biases = graph.get_tensor_by_name(\"output/B:0\")\n",
    "        print('Fc_4', fc_4_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_5_weights = graph.get_tensor_by_name(\"fc_5/W:0\")\n",
    "        fc_5_biases = graph.get_tensor_by_name(\"fc_5/B:0\")\n",
    "        print('Fc_5', fc_5_weights.shape)\n",
    "    except: pass\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    \n",
    "    #tf_prediction_dataset = tf.constant(images, name='prediction_data')\n",
    "    tf_prediction_dataset = tf.placeholder(tf.float32, shape=(batch_size, 46, 45, 1), name='training_data')        \n",
    "\n",
    "    g_preds_1 = []\n",
    "    g_preds_2 = []\n",
    "    h_preds_1 = []\n",
    "    h_preds_2 = []\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    name = model_folder_name.split('_')[-1]\n",
    "    for images in batchYielder('Gamma'):\n",
    "        feed_dict = {tf_prediction_dataset : images}\n",
    "        \n",
    "        if name=='cff':\n",
    "            with tf.name_scope('prediction_cff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')        \n",
    "                shape = pool_1.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_1, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cff, feed_dict=feed_dict)\n",
    "            \n",
    "        elif name=='ccff':\n",
    "            with tf.name_scope('prediction_ccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_2.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_ccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_ccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccff':\n",
    "            with tf.name_scope('prediction_cccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccfff':\n",
    "            with tf.name_scope('prediction_cccfff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "                prediction_cccfff = tf.nn.softmax(tf.matmul(hidden, fc_3_weights) + fc_3_biases)\n",
    "            pred = sess.run(prediction_cccfff, feed_dict=feed_dict)\n",
    "            \n",
    "        elif name=='ccccccffff':\n",
    "            with tf.name_scope('prediction_ccccccffff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_4 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_3, conv2d_4_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_4_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_5 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_4, conv2d_5_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_5_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_6 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_5, conv2d_6_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_6_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_6.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_6, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_3_weights) + fc_3_biases)\n",
    "                prediction_ccccccffff = tf.nn.softmax(tf.matmul(hidden, fc_4_weights) + fc_4_biases)\n",
    "            pred = sess.run(prediction_ccccccffff, feed_dict=feed_dict)\n",
    "        \n",
    "        else:\n",
    "            print('else', name)\n",
    "            break        \n",
    "\n",
    "        g_preds_1.extend(pred[:,0])\n",
    "        g_preds_2.extend(pred[:,1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    for images in batchYielder('Hadron'):\n",
    "        feed_dict = {tf_prediction_dataset : images}\n",
    "        \n",
    "        if name=='cff':\n",
    "            with tf.name_scope('prediction_cff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')        \n",
    "                shape = pool_1.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_1, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cff, feed_dict=feed_dict)\n",
    "            \n",
    "        elif name=='ccff':\n",
    "            with tf.name_scope('prediction_ccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_2.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_ccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_ccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccff':\n",
    "            with tf.name_scope('prediction_cccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccfff':\n",
    "            with tf.name_scope('prediction_cccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "                prediction_cccfff = tf.nn.softmax(tf.matmul(hidden, fc_3_weights) + fc_3_biases)\n",
    "            pred = sess.run(prediction_cccfff, feed_dict=feed_dict)\n",
    "            \n",
    "        elif name=='ccccccffff':\n",
    "            with tf.name_scope('prediction_ccccccffff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_4 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_3, conv2d_4_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_4_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_5 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_4, conv2d_5_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_5_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_6 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_5, conv2d_6_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_6_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_6.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_6, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_3_weights) + fc_3_biases)\n",
    "                prediction_ccccccffff = tf.nn.softmax(tf.matmul(hidden, fc_4_weights) + fc_4_biases)\n",
    "            pred = sess.run(prediction_ccccccffff, feed_dict=feed_dict)\n",
    "        \n",
    "        else:\n",
    "            print('else', name)\n",
    "            break        \n",
    "\n",
    "        h_preds_1.extend(pred[:,0])\n",
    "        h_preds_2.extend(pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_data = list(zip(g_preds_1, g_preds_2))\n",
    "h_data = list(zip(h_preds_1, h_preds_2))\n",
    "g_df = pd.DataFrame(g_data, columns=['Hadron', 'Gamma'])\n",
    "h_df = pd.DataFrame(h_data, columns=['Hadron', 'Gamma'])\n",
    "#df.to_csv(prediction_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncP8FRbyEwE8ivJ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3c4f476d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bins = np.arange(0,1.01,0.01)\n",
    "ax = g_df.hist(['Gamma'], bins=bins, alpha=0.75)\n",
    "h_df.hist(['Gamma'], bins=bins, ax=ax, alpha=0.75)\n",
    "plt.yscale('log')\n",
    "plt.legend(['Gamma', 'Hadron'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475000\n",
      "475000\n"
     ]
    }
   ],
   "source": [
    "print(len(g_data))\n",
    "print(len(h_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56636820751911365"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "g_df['Real']=1\n",
    "h_df['Real']=0\n",
    "\n",
    "df = pd.concat([g_df, h_df])\n",
    "\n",
    "stop_auc = roc_auc_score(df['Real'].values, df['Gamma'].values)\n",
    "stop_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
