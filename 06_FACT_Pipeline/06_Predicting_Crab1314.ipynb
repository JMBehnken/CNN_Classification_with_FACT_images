{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predicting Crab1314\n",
    "\n",
    "The preprocessed Crab1314 data will be fed into the best model in the assigned folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_folder_name = '13_cccfff'\n",
    "batch_size = 10000\n",
    "\n",
    "main_path = '/fhgfs/users/jbehnken/01_Data/04_Models'\n",
    "meta_loading_folder = os.path.join(main_path, model_folder_name)\n",
    "meta_loading_path = os.path.join(main_path, model_folder_name, model_folder_name.split('_')[-1] + '.meta')\n",
    "prediction_save_path = os.path.join(main_path, model_folder_name, model_folder_name.split('_')[-1] + '_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batchYielder():\n",
    "    with h5py.File('/fhgfs/users/jbehnken/01_Data/02_Crab_Prediction/Crab1314_Images.h5', 'r') as hdf:\n",
    "        items = list(hdf.items())[0][1].shape[0]\n",
    "        i = 0\n",
    "\n",
    "        while (i+1)*batch_size < items/1: # 160 factor to not process everything\n",
    "            night = np.array(hdf['Night'][ i*batch_size:(i+1)*batch_size ])\n",
    "            run = np.array(hdf['Run'][ i*batch_size:(i+1)*batch_size ])\n",
    "            event = np.array(hdf['Event'][ i*batch_size:(i+1)*batch_size ])\n",
    "            images = np.array(hdf['Image'][ i*batch_size:(i+1)*batch_size ])\n",
    "\n",
    "            i += 1\n",
    "            print(i)\n",
    "            yield (night, run, event, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gpu_config = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.55)\n",
    "session_conf = tf.ConfigProto(gpu_options=gpu_config, intra_op_parallelism_threads=18, inter_op_parallelism_threads=18)\n",
    "\n",
    "\n",
    "with tf.Session(config=session_conf) as sess:\n",
    "    saver = tf.train.import_meta_graph(meta_loading_path)    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint(meta_loading_folder))\n",
    "    \n",
    "    graph = tf.get_default_graph() \n",
    "    try:\n",
    "        conv2d_1_weights = graph.get_tensor_by_name(\"conv2d_1/W:0\")\n",
    "        conv2d_1_biases = graph.get_tensor_by_name(\"conv2d_1/B:0\")\n",
    "        print('Conv2d_1', conv2d_1_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_2_weights = graph.get_tensor_by_name(\"conv2d_2/W:0\")\n",
    "        conv2d_2_biases = graph.get_tensor_by_name(\"conv2d_2/B:0\")\n",
    "        print('Conv2d_2', conv2d_2_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_3_weights = graph.get_tensor_by_name(\"conv2d_3/W:0\")\n",
    "        conv2d_3_biases = graph.get_tensor_by_name(\"conv2d_3/B:0\")\n",
    "        print('Conv2d_3', conv2d_3_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_4_weights = graph.get_tensor_by_name(\"conv2d_4/W:0\")\n",
    "        conv2d_4_biases = graph.get_tensor_by_name(\"conv2d_4/B:0\")\n",
    "        print('Conv2d_4', conv2d_4_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        conv2d_5_weights = graph.get_tensor_by_name(\"conv2d_5/W:0\")\n",
    "        conv2d_5_biases = graph.get_tensor_by_name(\"conv2d_5/B:0\")\n",
    "        print('Conv2d_5', conv2d_5_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_1_weights = graph.get_tensor_by_name(\"fc_1/W:0\")\n",
    "        fc_1_biases = graph.get_tensor_by_name(\"fc_1/B:0\")\n",
    "        print('Fc_1', fc_1_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_2_weights = graph.get_tensor_by_name(\"fc_2/W:0\")\n",
    "        fc_2_biases = graph.get_tensor_by_name(\"fc_2/B:0\")\n",
    "        print('Fc_2', fc_2_weights.shape)\n",
    "    except: pass\n",
    "    \n",
    "    try:\n",
    "        fc_3_weights = graph.get_tensor_by_name(\"fc_3/W:0\")\n",
    "        fc_3_biases = graph.get_tensor_by_name(\"fc_3/B:0\")\n",
    "        print('Fc_3', fc_3_weights.shape)\n",
    "    except: pass\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    \n",
    "    #tf_prediction_dataset = tf.constant(images, name='prediction_data')\n",
    "    tf_prediction_dataset = tf.placeholder(tf.float32, shape=(batch_size, 46, 45, 1), name='training_data')        \n",
    "    \n",
    "    nights = []\n",
    "    runs = []\n",
    "    events = []\n",
    "    preds_1 = []\n",
    "    preds_2 = []\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    name = model_folder_name.split('_')[-1]\n",
    "    for batch in batchYielder():\n",
    "        night, run, event, images = batch\n",
    "        feed_dict = {tf_prediction_dataset : images}\n",
    "        \n",
    "        if name=='cff':\n",
    "            with tf.name_scope('prediction_cff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')        \n",
    "                shape = pool_1.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_1, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cff, feed_dict=feed_dict)\n",
    "            \n",
    "        elif name=='ccff':\n",
    "            with tf.name_scope('prediction_ccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_2.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_ccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_ccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccff':\n",
    "            with tf.name_scope('prediction_cccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                prediction_cccff = tf.nn.softmax(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "            pred = sess.run(prediction_cccff, feed_dict=feed_dict)\n",
    "        \n",
    "        elif name=='cccfff':\n",
    "            with tf.name_scope('prediction_cccff'):\n",
    "                pool_1 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(tf_prediction_dataset, conv2d_1_weights, [1, 1, 1, 1], padding='SAME') + conv2d_1_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_2 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_1, conv2d_2_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_2_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                pool_3 = tf.nn.max_pool(tf.nn.relu(tf.nn.conv2d(pool_2, conv2d_3_weights, [1, 1, 1, 1], padding='SAME')  + conv2d_3_biases), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                shape = pool_3.get_shape().as_list()\n",
    "                reshape = tf.reshape(pool_3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "                hidden = tf.nn.relu(tf.matmul(reshape, fc_1_weights) + fc_1_biases)\n",
    "                hidden = tf.nn.relu(tf.matmul(hidden, fc_2_weights) + fc_2_biases)\n",
    "                prediction_cccfff = tf.nn.softmax(tf.matmul(hidden, fc_3_weights) + fc_3_biases)\n",
    "            pred = sess.run(prediction_cccfff, feed_dict=feed_dict)\n",
    "        \n",
    "        else:\n",
    "            break        \n",
    "        \n",
    "        nights.extend(night)\n",
    "        runs.extend(run)\n",
    "        events.extend(event)\n",
    "        preds_1.extend(pred[:,0])\n",
    "        preds_2.extend(pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = list(zip(nights, runs, events, preds_1, preds_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Night', 'Run','Event', 'Proton', 'Gamma'])\n",
    "df.to_csv(prediction_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
